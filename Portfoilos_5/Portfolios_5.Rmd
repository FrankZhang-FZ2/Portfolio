---
title: "Portfolios_5"
author: "Qilin Zhang"
date: "2023-04-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
```

```{r pac, message = FALSE, include=FALSE}
library(summarytools)
library(tidyverse) #data wrangling
library(codebook) #codebook generation
library(future) #reliability
library(ufs) #reliability
library(GGally) #reliability
library(GPArotation) #reliability
library(rio) #reading in different file types
library(labelled) #labeling data
library(psych)
library(corrplot) 
library("psych")
library(mirt)
library(eRm)
library(mice)
library(lavaan)
library(semPlot)
library(parameters)
library(broom)
library(likert)
library(sjPlot)

#if need to download the epmr package
#if (!require("devtools")) install.packages("devtools")   
#devtools::install_github("talbano/epmr")
```

###cleaning

```{r cleaning code, include = FALSE}

## use other read functions as appropriate for file type

dict <- rio::import(file = "DGS_S1_dictionary.xlsx") #dictionary

data <- read.csv(file = 'DGS_S1_Deidentified For Analyses.csv', sep = ",") #data

##trim based on completion time (>180)
data <- data %>%
  filter(Duration..in.seconds. >= 180)

data <- data[-c(1:2),-c(1:7)]

## Variable types 
names <- dict %>% 
  filter(type == "character") %>% 
  pull(variable)
data[,names] <- 
  lapply(data[,names], as.character)

names <- dict %>% 
  filter(type == "factor") %>% 
  pull(variable)
data[,names] <- 
  lapply(data[,names], as.numeric) #factor variables are coded as numeric for codebook purposes

names <- dict %>% 
  filter(type == "numeric") %>% 
  pull(variable)
data[,names] <- 
  lapply(data[,names], as.numeric)

rm(names)

##data completion check and imputation

#remove failed attention check -55 participants from this process
data <- data %>%
  filter(DGS_31 == 4) %>%
  filter((DGS_53 == 2))

#prepare dataframe for different scales
DGS <- data[grep("DGS_1",colnames(data)):grep("DGS_75",colnames(data))] %>%
  select(!c(DGS_31,DGS_53))


##remove people that gave 90% of the same answer in DGS

for(i in 1:7){
  percent <- function(x){
  sum((x == i)/length(x)*100)
  }
  number <- apply(DGS,1,percent)
  data <- data[c(number<90),]
}

#function for checking percentage of missing data (unit=%)
percent_missing <- function(x){
  sum(is.na((x))/length(x)*100)
}
missing_R <- apply(data,1,percent_missing)
table(missing_R)

#use if don't want imputation(turn off if I need imputation)
replace_rows <- subset(data, missing_R<=0)
data <- replace_rows
```

```{r imputation, include= FALSE}
if(FALSE){
#subset based on filtering criteria
replace_rows <- subset(data, missing_R<=10)
no_rows <- subset(data, missing_R>10)

missing_C <- apply(replace_rows,2,percent_missing)
table(missing_C) #no concern here

replace_data <- replace_rows[,1:85]
leftout <- replace_rows[,86:91]

#check where the NAs are if needed
rindex <- rep(FALSE, nrow(replace_data))
for (i in 1:nrow(replace_data)){
  for (j in 1:grep("DGS_75",colnames(replace_data))){
    if( is.na(replace_data[i,j])){
      rindex[i] = TRUE
      j = ncol(replace_data)+1
    }
  }
}
data_error <- replace_data[rindex,]

rm(data_error)
#imputation
temp <- mice(replace_data)
fixed_data <- complete(temp)  #imputation using mice package
data <- cbind(fixed_data,leftout) #no additional participants were removed

rm(fixed_data,leftout,no_rows,replace_data,replace_rows)
}
```

```{r recode, include=FALSE}
##recode

#DGS recode
likert <- dict %>% 
  filter (value_label == "1 = Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither agree nor disagree, 5 = Somewhat agree, 6 = Agree, 7 = Strongly agree") %>%
  pull(variable)
add_likert <- function(x) {
  val_labels(x) <- c("Strongly disagree"= 1, "Disagree" = 2, "Somewhat disagree" = 3, "Neither agree nor disagree" = 4, "Somewhat agree" = 5, "Agree" = 6, "Strongly agree" = 7) 
  x
}
data <- data %>%
  mutate_at(likert, 
            add_likert)  

rm(likert, add_likert)

#HEXACO_C

likert <- dict %>% 
  filter (value_label == "1 = Strongly disagree, 2 = Somewhat disagree, 3 = Neither agree nor disagree, 4 = Somewhat agree, 5 = Strongly agree") %>%
  pull(variable)
add_likert <- function(x) {
  val_labels(x) <- c("Strongly disagree"= 1, "Somewhat disagree" = 2, "Neither agree nor disagree" = 3, "Somewhat agree" = 4, "Strongly agree" = 5) 
  x
}
data <- data %>%
  mutate_at(likert, 
            add_likert)  

rm(likert, add_likert)

## Reverse-scoring 
reversed_items <- dict %>%  #make a list of reversed items
 filter (keying == -1) %>% 
 pull(variable)

data <- data %>%  #reverse values in data
  mutate_at(reversed_items,
          reverse_labelled_values)

rm(reversed_items)

##scale construction

## Variable labels
var_label(data) <- dict %>% 
  select(variable, label) %>% 
  dict_to_list()

rm(extra)

##DGS
DGS <- dict %>% 
  filter (scale == "DGS") %>% 
  pull(variable)

data$DGS <- data %>% 
  select(all_of(DGS)) %>% 
  aggregate_and_document_scale()

##HEXACO_C

HEXACO_C <- dict %>% 
  filter (scale == "HEXACO_C") %>% 
  pull(variable)

data$HEXACO_C <- data %>% 
  select(all_of(HEXACO_C)) %>% 
  aggregate_and_document_scale()

###7 factors model
M7_1 <- dict %>% 
  filter (M7_concise == 1) %>% 
  pull(variable)
M7_2 <- dict %>% 
  filter (M7_concise == 2) %>% 
  pull(variable)
M7_3 <- dict %>% 
  filter (M7_concise == 3) %>% 
  pull(variable)
M7_4 <- dict %>% 
  filter (M7_concise == 4) %>% 
  pull(variable)
M7_5 <- dict %>% 
  filter (M7_concise == 5) %>% 
  pull(variable)
M7_6 <- dict %>% 
  filter (M7_concise == 6) %>% 
  pull(variable)
M7_7 <- dict %>% 
  filter (M7_concise == 7) %>% 
  pull(variable)

###7 factors model

data$M7_1 <- data %>% 
  select(all_of(M7_1)) %>% 
  aggregate_and_document_scale()

data$M7_2 <- data %>% 
  select(all_of(M7_2)) %>% 
  aggregate_and_document_scale()

data$M7_3 <- data %>% 
  select(all_of(M7_3)) %>% 
  aggregate_and_document_scale()

data$M7_4 <- data %>% 
  select(all_of(M7_4)) %>% 
  aggregate_and_document_scale()

data$M7_5 <- data %>% 
  select(all_of(M7_5)) %>% 
  aggregate_and_document_scale()

data$M7_6 <- data %>% 
  select(all_of(M7_6)) %>% 
  aggregate_and_document_scale()

data$M7_7 <- data %>% 
  select(all_of(M7_7)) %>% 
  aggregate_and_document_scale()
```

```{r preparation}

##rename
data_cleaned <- data

#prepare dataframe for different scales
DGS <- data_cleaned[grep("DGS_1",colnames(data_cleaned)):grep("DGS_75",colnames(data_cleaned))]
DGS <- DGS[,-c(grep("DGS_31",colnames(DGS)),grep("DGS_53",colnames(DGS)))]

HEXACO_C <- data_cleaned[grep("HEXACO_C_1",colnames(data_cleaned)):grep("HEXACO_C_10",colnames(data_cleaned))]
```

###IRT

```{r assign}
#6 factors model without behavioral items
DGS_6model_1 <- DGS %>%
  select(c(DGS_4,DGS_12,DGS_15,DGS_17,DGS_18,DGS_19,DGS_22,DGS_30,DGS_32,DGS_33,DGS_34,DGS_36,DGS_56,DGS_49,DGS_57,DGS_58,DGS_60,DGS_61,DGS_63,DGS_74,DGS_75))
DGS_6model_2 <- DGS %>%
  select(c(DGS_5,DGS_10,DGS_26,DGS_41,DGS_54,DGS_69,DGS_72))
DGS_6model_3 <- DGS %>%
  select(c(DGS_9,DGS_20,DGS_27,DGS_29,DGS_46,DGS_52))
DGS_6model_4 <- DGS %>%
  select(c(DGS_2,DGS_11,DGS_28,DGS_35,DGS_48,DGS_68))
DGS_6model_5 <- DGS %>%
  select(c(DGS_1,DGS_21,DGS_44,DGS_65))
DGS_6model_6 <- DGS %>%
  select(c(DGS_6,DGS_38,DGS_39,DGS_45,DGS_67,DGS_70,DGS_71))

```

## 6 factors (dropping rule is loading in IFA < 0.3)

```{R IRT6_1}
DGS_IRT6_1 = mirt(data = DGS_6model_1,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_1)
coef(DGS_IRT6_1, IRTpars = T)
itemplot(DGS_IRT6_1,10, type = "trace",
         main = "Probability function for DGS_33")
plot(DGS_IRT6_1, type = "trace")
plot(DGS_IRT6_1, type = "info")
plot(DGS_IRT6_1) #expected score curve


##recommend taking out 4 and 22
DGS_6model_1 <- DGS_6model_1%>%
  select(!c(DGS_4,DGS_22))

DGS_IRT6_1 = mirt(data = DGS_6model_1,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_1)
plot(DGS_IRT6_1, type = "trace")
#traces suggest that 2-4 options were not commonly used
plot(DGS_IRT6_1, type = "info")
#item information suggests that we need to improve the ability to identify people on top of the altruism scores. 


#person fit
#fscores(DGS_IRT6_1) #factor score for each participants
#mirt::itemfit(DGS_IRT6_1)
#mirt::personfit(DGS_IRT6_1)
```

```{R IRT6_2}
DGS_IRT6_2 = mirt(data = DGS_6model_2,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_2)
coef(DGS_IRT6_2, IRTpars = T)
plot(DGS_IRT6_2, type = "trace")
plot(DGS_IRT6_2, type = "info")
plot(DGS_IRT6_2) #expected score curve

#person fit
#fscores(DGS_IRT6_2) #factor score for each participants
#mirt::itemfit(DGS_IRT6_2)
#mirt::personfit(DGS_IRT6_2)

```

```{R IRT6_3}
DGS_IRT6_3 = mirt(data = DGS_6model_3,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_3)
coef(DGS_IRT6_3, IRTpars = T)
plot(DGS_IRT6_3, type = "trace")
plot(DGS_IRT6_3, type = "info")
plot(DGS_IRT6_3) #expected score curve

# suggest remove 20
DGS_6model_3 <- DGS_6model_3%>%
  select(!c(DGS_20))
DGS_IRT6_3 = mirt(data = DGS_6model_3,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_3)

#person fit
#fscores(DGS_IRT6_3) #factor score for each participants
#mirt::itemfit(DGS_IRT6_3)
#mirt::personfit(DGS_IRT6_3)
```

```{R IRT6_4}
DGS_IRT6_4 = mirt(data = DGS_6model_4,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_4)
coef(DGS_IRT6_4, IRTpars = T)
plot(DGS_IRT6_4, type = "trace")
plot(DGS_IRT6_4, type = "info")
plot(DGS_IRT6_4) #expected score curve

#suggest remove 2, 11 due to poor discrimination
DGS_6model_4 <- DGS_6model_4 %>%
  select(!c(DGS_2,DGS_11))
DGS_IRT6_4 = mirt(data = DGS_6model_4,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_4)

#person fit
#fscores(DGS_IRT6_4) #factor score for each participants
#mirt::itemfit(DGS_IRT6_4)
#mirt::personfit(DGS_IRT6_4)

```

```{R IRT6_5}
DGS_IRT6_5 = mirt(data = DGS_6model_5,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_5)
coef(DGS_IRT6_5, IRTpars = T)
plot(DGS_IRT6_5, type = "trace")
plot(DGS_IRT6_5, type = "info")
plot(DGS_IRT6_5) #expected score curve

#suggest dropping 1
DGS_6model_5 <- DGS_6model_5 %>%
  select(!c(DGS_1))
DGS_IRT6_5 = mirt(data = DGS_6model_5,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_5)


#person fit
#fscores(DGS_IRT6_5) #factor score for each participants
#mirt::itemfit(DGS_IRT6_5)
#mirt::personfit(DGS_IRT6_5)

```

```{R IRT6_6}
DGS_IRT6_6 = mirt(data = DGS_6model_6,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_6)
coef(DGS_IRT6_6, IRTpars = T)
itemplot(DGS_IRT6_6, 1, type = "trace",
         main = "probability function for DGS_6")
plot(DGS_IRT6_6, type = "trace")
plot(DGS_IRT6_6, type = "info")
plot(DGS_IRT6_6) #expected score curve

#suggest dropping 45
DGS_6model_6 <- DGS_6model_6 %>%
  select(!c(DGS_45))
DGS_IRT6_6 = mirt(data = DGS_6model_6,
      model = 1, #this is for one factor
      itemtype = "gpcmIRT" #generalized partial credit model
)
summary(DGS_IRT6_6)
#need some thoughts and modification here. The categorical imperative items are not lumping very well together. 

#person fit
#fscores(DGS_IRT6_6) #factor score for each participants
#mirt::itemfit(DGS_IRT6_6)
#mirt::personfit(DGS_IRT6_6)

```
